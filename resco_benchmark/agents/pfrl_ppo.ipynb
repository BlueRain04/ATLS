{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6351abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from pfrl.nn import Branched\n",
    "import pfrl.initializers\n",
    "from pfrl.agents import PPO\n",
    "from pfrl.policies import SoftmaxCategoricalHead\n",
    "\n",
    "from resco_benchmark.agents.agent import IndependentAgent, Agent\n",
    "\n",
    "\n",
    "def lecun_init(layer, gain=1):\n",
    "    if isinstance(layer, (nn.Conv2d, nn.Linear)):\n",
    "        pfrl.initializers.init_lecun_normal(layer.weight, gain)\n",
    "        nn.init.zeros_(layer.bias)\n",
    "    else:\n",
    "        pfrl.initializers.init_lecun_normal(layer.weight_ih_l0, gain)\n",
    "        pfrl.initializers.init_lecun_normal(layer.weight_hh_l0, gain)\n",
    "        nn.init.zeros_(layer.bias_ih_l0)\n",
    "        nn.init.zeros_(layer.bias_hh_l0)\n",
    "    return layer\n",
    "\n",
    "\n",
    "class IPPO(IndependentAgent):\n",
    "    def __init__(self, config, obs_act, map_name, thread_number):\n",
    "        super().__init__(config, obs_act, map_name, thread_number)\n",
    "        for key in obs_act:\n",
    "            obs_space = obs_act[key][0]\n",
    "            act_space = obs_act[key][1]\n",
    "            self.agents[key] = PFRLPPOAgent(config, obs_space, act_space)\n",
    "            if self.config['load']:\n",
    "                print('LOADING SAVED MODEL FOR EVALUATION')\n",
    "                self.agents[key].load(self.config['log_dir']+'agent_'+key+'.pt')\n",
    "                self.agents[key].agent.training = False\n",
    "\n",
    "\n",
    "class PFRLPPOAgent(Agent):\n",
    "    def __init__(self, config, obs_space, act_space):\n",
    "        super().__init__()\n",
    "\n",
    "        def conv2d_size_out(size, kernel_size=2, stride=1):\n",
    "            return (size - (kernel_size - 1) - 1) // stride + 1\n",
    "\n",
    "        h = conv2d_size_out(obs_space[1])\n",
    "        w = conv2d_size_out(obs_space[2])\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            lecun_init(nn.Conv2d(obs_space[0], 64, kernel_size=(2, 2))),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            lecun_init(nn.Linear(h*w*64, 64)),\n",
    "            nn.ReLU(),\n",
    "            lecun_init(nn.Linear(64, 64)),\n",
    "            nn.ReLU(),\n",
    "            Branched(\n",
    "                nn.Sequential(\n",
    "                    lecun_init(nn.Linear(64, act_space), 1e-2),\n",
    "                    SoftmaxCategoricalHead()\n",
    "                ),\n",
    "                lecun_init(nn.Linear(64, 1))\n",
    "            )\n",
    "        )\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=2.5e-4, eps=1e-5)\n",
    "        self.agent = PPO(self.model, self.optimizer, gpu=self.device.index,\n",
    "                         phi=lambda x: np.asarray(x, dtype=np.float32),\n",
    "                         clip_eps=0.1,\n",
    "                         clip_eps_vf=None,\n",
    "                         update_interval=1024,\n",
    "                         minibatch_size=256,\n",
    "                         epochs=4,\n",
    "                         standardize_advantages=True,\n",
    "                         entropy_coef=0.001,\n",
    "                         max_grad_norm=0.5)\n",
    "\n",
    "    def act(self, observation):\n",
    "        return self.agent.act(observation)\n",
    "\n",
    "    def observe(self, observation, reward, done, info):\n",
    "        self.agent.observe(observation, reward, done, False)\n",
    "\n",
    "    def save(self, path):\n",
    "        torch.save({\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "        }, path+'.pt')\n",
    "\n",
    "    def load(self, path):\n",
    "        self.model.load_state_dict(torch.load(path)['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(torch.load(path)['optimizer_state_dict'])\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
