{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fe87c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from resco_benchmark.config.signal_config import signal_configs\n",
    "from resco_benchmark.agents.agent import Agent\n",
    "\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from resco_benchmark.agents.ma2c import MA2CAgent\n",
    "except ImportError:\n",
    "    tf = None\n",
    "    pass\n",
    "\n",
    "if tf is None:\n",
    "    class FMA2C(Agent):\n",
    "        def __init__(self, config, obs_act, map_name, thread_number):\n",
    "            super().__init__()\n",
    "            raise EnvironmentError(\"Install optional tensorflow requirement for FMA2C\")\n",
    "\n",
    "else:\n",
    "\n",
    "    class FMA2C(Agent):\n",
    "        def __init__(self, config, obs_act, map_name, thread_number):\n",
    "            super().__init__()\n",
    "            self.config = config\n",
    "\n",
    "            tf.reset_default_graph()\n",
    "            cfg_proto = tf.ConfigProto(allow_soft_placement=True)\n",
    "            self.sess = tf.Session(config=cfg_proto)\n",
    "\n",
    "            self.signal_config = signal_configs[map_name]\n",
    "            self.supervisors = config['mdp']['supervisors']  # reverse of management\n",
    "            self.management_neighbors = config['mdp']['management_neighbors']\n",
    "            management = config['mdp']['management']\n",
    "\n",
    "            self.state = None\n",
    "            self.acts = None\n",
    "\n",
    "            self.managers = dict()\n",
    "            self.workers = dict()\n",
    "\n",
    "            for manager in management:\n",
    "                worker_ids = management[manager]\n",
    "                mgr_act_size = self.config['management_acts']\n",
    "                mgr_fingerprint_size = len(self.management_neighbors[manager]) * mgr_act_size\n",
    "                self.managers[manager] = MA2CAgent(config, obs_act[manager][0], mgr_act_size, mgr_fingerprint_size, 0,\n",
    "                                                   manager + str(thread_number), self.sess)\n",
    "\n",
    "                for worker_id in worker_ids:\n",
    "                    # Get fingerprint size\n",
    "                    downstream = self.signal_config[worker_id]['downstream']\n",
    "                    neighbors = [downstream[direction] for direction in downstream]\n",
    "                    fp_size = 0\n",
    "                    for neighbor in neighbors:\n",
    "                        if neighbor is not None and self.supervisors[neighbor] == self.supervisors[worker_id]:\n",
    "                            fp_size += obs_act[neighbor][1]  # neighbor's action size\n",
    "\n",
    "                    # Get waiting size\n",
    "                    lane_sets = self.signal_config[worker_id]['lane_sets']\n",
    "                    lanes = []\n",
    "                    for direction in lane_sets:\n",
    "                        for lane in lane_sets[direction]:\n",
    "                            if lane not in lanes: lanes.append(lane)\n",
    "                    waits_len = len(lanes)\n",
    "\n",
    "                    management_size = len(self.management_neighbors[manager])+1\n",
    "\n",
    "                    observation_shape = (obs_act[worker_id][0][0] + management_size,)\n",
    "                    num_actions = obs_act[worker_id][1]\n",
    "                    self.workers[worker_id] = MA2CAgent(config, observation_shape, num_actions, fp_size, waits_len,\n",
    "                                                        worker_id + str(thread_number), self.sess)\n",
    "\n",
    "            self.saver = tf.train.Saver(max_to_keep=1)\n",
    "            self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        def fingerprints(self, observation):\n",
    "            agent_fingerprint = {}\n",
    "            for agent_id in observation.keys():\n",
    "                if agent_id in self.managers:\n",
    "                    fingerprints = []\n",
    "                    for neighbor in self.management_neighbors[agent_id]:\n",
    "                        neighbor_fp = self.managers[neighbor].fingerprint\n",
    "                        fingerprints.append(neighbor_fp)\n",
    "                    if len(fingerprints) > 0:\n",
    "                        fp = np.concatenate(fingerprints)\n",
    "                    else:\n",
    "                        fp = np.asarray([])\n",
    "                    agent_fingerprint[agent_id] = fp\n",
    "                else:\n",
    "                    downstream = self.signal_config[agent_id]['downstream']\n",
    "                    neighbors = [downstream[direction] for direction in downstream]\n",
    "                    fingerprints = []\n",
    "                    for neighbor in neighbors:\n",
    "                        if neighbor is not None and self.supervisors[neighbor] == self.supervisors[agent_id]:\n",
    "                            neighbor_fp = self.workers[neighbor].fingerprint\n",
    "                            fingerprints.append(neighbor_fp)\n",
    "                    if len(fingerprints) > 0:\n",
    "                        fp = np.concatenate(fingerprints)\n",
    "                    else:\n",
    "                        fp = np.asarray([])\n",
    "                    agent_fingerprint[agent_id] = fp\n",
    "            return agent_fingerprint\n",
    "\n",
    "        def act(self, observation):\n",
    "            acts = dict()\n",
    "            full_state = dict()     # Includes fingerprints, but not manager acts\n",
    "            fingerprints = self.fingerprints(observation)\n",
    "            # First get management's acts, they're part of the state for workers\n",
    "            for agent_id in self.managers:\n",
    "                env_obs = observation[agent_id]\n",
    "                neighbor_fingerprints = fingerprints[agent_id]\n",
    "                combine = np.concatenate([env_obs, neighbor_fingerprints])\n",
    "                acts[agent_id] = self.managers[agent_id].act(combine)\n",
    "\n",
    "            for agent_id in self.workers:\n",
    "                env_obs = observation[agent_id]\n",
    "                neighbor_fingerprints = fingerprints[agent_id]\n",
    "\n",
    "                combine = np.concatenate([env_obs, neighbor_fingerprints])\n",
    "                full_state[agent_id] = combine\n",
    "\n",
    "                # Get management goals\n",
    "                managing_agent = self.supervisors[agent_id]\n",
    "                managing_agents_acts = [acts[managing_agent]]\n",
    "                for mgr_neighbor in self.management_neighbors[managing_agent]:\n",
    "                    managing_agents_acts.append(acts[mgr_neighbor])\n",
    "                managing_agents_acts = np.asarray(managing_agents_acts)\n",
    "                combine = np.concatenate([managing_agents_acts, combine])\n",
    "\n",
    "                acts[agent_id] = self.workers[agent_id].act(combine)\n",
    "            self.state = full_state\n",
    "            self.acts = acts\n",
    "            return acts\n",
    "\n",
    "        def observe(self, observation, reward, done, info):\n",
    "            fingerprints = self.fingerprints(observation)\n",
    "\n",
    "            for agent_id in observation.keys():\n",
    "                env_obs = observation[agent_id]\n",
    "                neighbor_fingerprints = fingerprints[agent_id]\n",
    "                combine = np.concatenate([env_obs, neighbor_fingerprints])\n",
    "\n",
    "                if agent_id in self.managers:\n",
    "                    rw = reward[agent_id]\n",
    "                    self.managers[agent_id].observe(combine, rw, done, info)\n",
    "                else:\n",
    "                    managing_agent = self.supervisors[agent_id]\n",
    "                    managing_agents_acts = [self.acts[managing_agent]]\n",
    "                    for mgr_neighbor in self.management_neighbors[managing_agent]:\n",
    "                        managing_agents_acts.append(self.acts[mgr_neighbor])\n",
    "                    managing_agents_acts = np.asarray(managing_agents_acts)\n",
    "                    combine = np.concatenate([managing_agents_acts, combine])\n",
    "                    self.workers[agent_id].observe(combine, reward[agent_id], done, info)\n",
    "\n",
    "                if done:\n",
    "                    if info['eps'] % 100 == 0:\n",
    "                        if self.saver is not None:\n",
    "                            self.saver.save(self.sess, self.config['log_dir'] + 'agent_' + 'checkpoint',\n",
    "                                            global_step=info['eps'])\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
