{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6421822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from resco_benchmark.agents.agent import SharedAgent\n",
    "from resco_benchmark.agents.pfrl_dqn import DQNAgent\n",
    "from resco_benchmark.config.signal_config import signal_configs\n",
    "from pfrl.q_functions import DiscreteActionValueHead\n",
    "\n",
    "\n",
    "class MPLight(SharedAgent):\n",
    "    def __init__(self, config, obs_act, map_name, thread_number):\n",
    "        super().__init__(config, obs_act, map_name, thread_number)\n",
    "        phase_pairs = signal_configs[map_name]['phase_pairs']\n",
    "        num_actions = len(phase_pairs)\n",
    "\n",
    "        comp_mask = []\n",
    "        for i in range(len(phase_pairs)):\n",
    "            zeros = np.zeros(len(phase_pairs) - 1, dtype=int)\n",
    "            cnt = 0\n",
    "            for j in range(len(phase_pairs)):\n",
    "                if i == j: continue\n",
    "                pair_a = phase_pairs[i]\n",
    "                pair_b = phase_pairs[j]\n",
    "                if len(list(set(pair_a + pair_b))) == 3: zeros[cnt] = 1\n",
    "                cnt += 1\n",
    "            comp_mask.append(zeros)\n",
    "        comp_mask = np.asarray(comp_mask)\n",
    "        print(comp_mask)\n",
    "\n",
    "        comp_mask = torch.from_numpy(comp_mask).to(self.device)\n",
    "        self.valid_acts = signal_configs[map_name]['valid_acts']\n",
    "        model = FRAP(config, num_actions, phase_pairs, comp_mask, self.device)\n",
    "        self.agent = DQNAgent(config, num_actions, model, num_agents=config['num_lights'])\n",
    "        if self.config['load']:\n",
    "            print('LOADING SAVED MODEL FOR EVALUATION')\n",
    "            self.agent.load(self.config['log_dir'] + 'agent.pt')\n",
    "            self.agent.agent.training = False\n",
    "\n",
    "\n",
    "class FRAP(nn.Module):\n",
    "    def __init__(self, config, output_shape, phase_pairs, competition_mask, device):\n",
    "        super(FRAP, self).__init__()\n",
    "        self.oshape = output_shape\n",
    "        self.phase_pairs = phase_pairs\n",
    "        self.comp_mask = competition_mask\n",
    "        self.device = device\n",
    "        self.demand_shape = config['demand_shape']      # Allows more than just queue to be used\n",
    "\n",
    "        self.d_out = 4      # units in demand input layer\n",
    "        self.p_out = 4      # size of phase embedding\n",
    "        self.lane_embed_units = 16\n",
    "        relation_embed_size = 4\n",
    "\n",
    "        self.p = nn.Embedding(2, self.p_out)\n",
    "        self.d = nn.Linear(self.demand_shape, self.d_out)\n",
    "\n",
    "        self.lane_embedding = nn.Linear(self.p_out + self.d_out, self.lane_embed_units)\n",
    "\n",
    "        self.lane_conv = nn.Conv2d(2*self.lane_embed_units, 20, kernel_size=(1, 1))\n",
    "\n",
    "        self.relation_embedding = nn.Embedding(2, relation_embed_size)\n",
    "        self.relation_conv = nn.Conv2d(relation_embed_size, 20, kernel_size=(1, 1))\n",
    "\n",
    "        self.hidden_layer = nn.Conv2d(20, 20, kernel_size=(1, 1))\n",
    "        self.before_merge = nn.Conv2d(20, 1, kernel_size=(1, 1))\n",
    "\n",
    "        self.head = DiscreteActionValueHead()\n",
    "\n",
    "    def forward(self, states):\n",
    "        states = states.to(self.device)\n",
    "        num_movements = int((states.size()[1]-1)/self.demand_shape)\n",
    "        batch_size = states.size()[0]\n",
    "        acts = states[:, 0].to(torch.int64)\n",
    "        states = states[:, 1:]\n",
    "        states = states.float()\n",
    "\n",
    "        # Expand action index to mark demand input indices\n",
    "        extended_acts = []\n",
    "        for i in range(batch_size):\n",
    "            act_idx = acts[i]\n",
    "            pair = self.phase_pairs[act_idx]\n",
    "            zeros = torch.zeros(num_movements, dtype=torch.int64, device=self.device)\n",
    "            zeros[pair[0]] = 1\n",
    "            zeros[pair[1]] = 1\n",
    "            extended_acts.append(zeros)\n",
    "        extended_acts = torch.stack(extended_acts)\n",
    "        phase_embeds = torch.sigmoid(self.p(extended_acts))\n",
    "\n",
    "        phase_demands = []\n",
    "        for i in range(num_movements):\n",
    "            phase = phase_embeds[:, i]  # size 4\n",
    "            demand = states[:, i:i+self.demand_shape]\n",
    "            demand = torch.sigmoid(self.d(demand))    # size 4\n",
    "            phase_demand = torch.cat((phase, demand), -1)\n",
    "            phase_demand_embed = F.relu(self.lane_embedding(phase_demand))\n",
    "            phase_demands.append(phase_demand_embed)\n",
    "        phase_demands = torch.stack(phase_demands, 1)\n",
    "\n",
    "        pairs = []\n",
    "        for pair in self.phase_pairs:\n",
    "            pairs.append(phase_demands[:, pair[0]] + phase_demands[:, pair[1]])\n",
    "\n",
    "        rotated_phases = []\n",
    "        for i in range(len(pairs)):\n",
    "            for j in range(len(pairs)):\n",
    "                if i != j: rotated_phases.append(torch.cat((pairs[i], pairs[j]), -1))\n",
    "        rotated_phases = torch.stack(rotated_phases, 1)\n",
    "        rotated_phases = torch.reshape(rotated_phases,\n",
    "                                       (batch_size, self.oshape, self.oshape - 1, 2 * self.lane_embed_units))\n",
    "        rotated_phases = rotated_phases.permute(0, 3, 1, 2)  # Move channels up\n",
    "        rotated_phases = F.relu(self.lane_conv(rotated_phases))  # Conv-20x1x1  pair demand representation\n",
    "\n",
    "        # Phase competition mask\n",
    "        competition_mask = self.comp_mask.tile((batch_size, 1, 1))\n",
    "        relations = F.relu(self.relation_embedding(competition_mask))\n",
    "        relations = relations.permute(0, 3, 1, 2)  # Move channels up\n",
    "        relations = F.relu(self.relation_conv(relations))  # Pair demand representation\n",
    "\n",
    "        # Phase pair competition\n",
    "        combine_features = rotated_phases * relations\n",
    "        combine_features = F.relu(self.hidden_layer(combine_features))  # Phase competition representation\n",
    "        combine_features = self.before_merge(combine_features)  # Pairwise competition result\n",
    "\n",
    "        # Phase score\n",
    "        combine_features = torch.reshape(combine_features, (batch_size, self.oshape, self.oshape - 1))\n",
    "        q_values = torch.sum(combine_features, dim=-1)\n",
    "        return self.head(q_values)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
